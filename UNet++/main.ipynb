{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## SETUP\n",
   "id": "83201e0ec1e6a781"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-25T13:52:49.910410Z",
     "start_time": "2024-11-25T13:51:02.071502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install numpy pandas matplotlib seaborn \n",
    "!pip install scikit-learn albumentations monai \n",
    "!pip install torch torchvision opencv-python\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in c:\\users\\igorj\\appdata\\roaming\\python\\python311\\site-packages (2.1.2)\n",
      "Requirement already satisfied: pandas in c:\\program files\\python311\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in c:\\program files\\python311\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: seaborn in c:\\program files\\python311\\lib\\site-packages (0.13.2)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting albumentations\n",
      "  Downloading albumentations-1.4.21-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting monai\n",
      "  Downloading monai-1.4.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: torch in c:\\program files\\python311\\lib\\site-packages (2.5.0)\n",
      "Requirement already satisfied: torchvision in c:\\program files\\python311\\lib\\site-packages (0.20.0)\n",
      "Requirement already satisfied: opencv-python in c:\\program files\\python311\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\program files\\python311\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\program files\\python311\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\igorj\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\program files\\python311\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\program files\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\program files\\python311\\lib\\site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\program files\\python311\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\program files\\python311\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\program files\\python311\\lib\\site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\program files\\python311\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\program files\\python311\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: PyYAML in c:\\program files\\python311\\lib\\site-packages (from albumentations) (6.0.2)\n",
      "Requirement already satisfied: pydantic>=2.7.0 in c:\\users\\igorj\\appdata\\roaming\\python\\python311\\site-packages (from albumentations) (2.9.2)\n",
      "Collecting albucore==0.0.20 (from albumentations)\n",
      "  Downloading albucore-0.0.20-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting eval-type-backport (from albumentations)\n",
      "  Downloading eval_type_backport-0.2.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in c:\\users\\igorj\\appdata\\roaming\\python\\python311\\site-packages (from albumentations) (4.10.0.84)\n",
      "Collecting stringzilla>=3.10.4 (from albucore==0.0.20->albumentations)\n",
      "  Downloading stringzilla-3.10.10-cp311-cp311-win_amd64.whl.metadata (81 kB)\n",
      "Collecting simsimd>=5.9.2 (from albucore==0.0.20->albumentations)\n",
      "  Downloading simsimd-6.1.1-cp311-cp311-win_amd64.whl.metadata (59 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\igorj\\appdata\\roaming\\python\\python311\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\program files\\python311\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\program files\\python311\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\igorj\\appdata\\roaming\\python\\python311\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\program files\\python311\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\program files\\python311\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\program files\\python311\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\igorj\\appdata\\roaming\\python\\python311\\site-packages (from pydantic>=2.7.0->albumentations) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\igorj\\appdata\\roaming\\python\\python311\\site-packages (from pydantic>=2.7.0->albumentations) (2.23.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\program files\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\igorj\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Downloading scikit_learn-1.5.2-cp311-cp311-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.0 MB 166.1 kB/s eta 0:01:04\n",
      "   - -------------------------------------- 0.5/11.0 MB 166.1 kB/s eta 0:01:04\n",
      "   - -------------------------------------- 0.5/11.0 MB 166.1 kB/s eta 0:01:04\n",
      "   - -------------------------------------- 0.5/11.0 MB 166.1 kB/s eta 0:01:04\n",
      "   - -------------------------------------- 0.5/11.0 MB 166.1 kB/s eta 0:01:04\n",
      "   - -------------------------------------- 0.5/11.0 MB 166.1 kB/s eta 0:01:04\n",
      "   - -------------------------------------- 0.5/11.0 MB 166.1 kB/s eta 0:01:04\n",
      "   -- ------------------------------------- 0.8/11.0 MB 171.2 kB/s eta 0:01:00\n",
      "   -- ------------------------------------- 0.8/11.0 MB 171.2 kB/s eta 0:01:00\n",
      "   -- ------------------------------------- 0.8/11.0 MB 171.2 kB/s eta 0:01:00\n",
      "   -- ------------------------------------- 0.8/11.0 MB 171.2 kB/s eta 0:01:00\n",
      "   --- ------------------------------------ 1.0/11.0 MB 198.1 kB/s eta 0:00:51\n",
      "   --- ------------------------------------ 1.0/11.0 MB 198.1 kB/s eta 0:00:51\n",
      "   --- ------------------------------------ 1.0/11.0 MB 198.1 kB/s eta 0:00:51\n",
      "   --- ------------------------------------ 1.0/11.0 MB 198.1 kB/s eta 0:00:51\n",
      "   ---- ----------------------------------- 1.3/11.0 MB 223.7 kB/s eta 0:00:44\n",
      "   ---- ----------------------------------- 1.3/11.0 MB 223.7 kB/s eta 0:00:44\n",
      "   ----- ---------------------------------- 1.6/11.0 MB 255.8 kB/s eta 0:00:37\n",
      "   ----- ---------------------------------- 1.6/11.0 MB 255.8 kB/s eta 0:00:37\n",
      "   ----- ---------------------------------- 1.6/11.0 MB 255.8 kB/s eta 0:00:37\n",
      "   ------ --------------------------------- 1.8/11.0 MB 269.1 kB/s eta 0:00:35\n",
      "   ------ --------------------------------- 1.8/11.0 MB 269.1 kB/s eta 0:00:35\n",
      "   ------ --------------------------------- 1.8/11.0 MB 269.1 kB/s eta 0:00:35\n",
      "   ------- -------------------------------- 2.1/11.0 MB 287.8 kB/s eta 0:00:31\n",
      "   ------- -------------------------------- 2.1/11.0 MB 287.8 kB/s eta 0:00:31\n",
      "   -------- ------------------------------- 2.4/11.0 MB 310.7 kB/s eta 0:00:28\n",
      "   --------- ------------------------------ 2.6/11.0 MB 332.6 kB/s eta 0:00:26\n",
      "   --------- ------------------------------ 2.6/11.0 MB 332.6 kB/s eta 0:00:26\n",
      "   --------- ------------------------------ 2.6/11.0 MB 332.6 kB/s eta 0:00:26\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 345.9 kB/s eta 0:00:24\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 345.9 kB/s eta 0:00:24\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 358.3 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 3.4/11.0 MB 383.5 kB/s eta 0:00:20\n",
      "   ------------- -------------------------- 3.7/11.0 MB 402.4 kB/s eta 0:00:19\n",
      "   -------------- ------------------------- 3.9/11.0 MB 420.2 kB/s eta 0:00:17\n",
      "   --------------- ------------------------ 4.2/11.0 MB 438.4 kB/s eta 0:00:16\n",
      "   --------------- ------------------------ 4.2/11.0 MB 438.4 kB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 4.5/11.0 MB 447.4 kB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 4.7/11.0 MB 470.6 kB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 4.7/11.0 MB 470.6 kB/s eta 0:00:14\n",
      "   ------------------- -------------------- 5.2/11.0 MB 501.2 kB/s eta 0:00:12\n",
      "   ------------------- -------------------- 5.5/11.0 MB 515.4 kB/s eta 0:00:11\n",
      "   --------------------- ------------------ 6.0/11.0 MB 550.9 kB/s eta 0:00:10\n",
      "   --------------------- ------------------ 6.0/11.0 MB 550.9 kB/s eta 0:00:10\n",
      "   --------------------- ------------------ 6.0/11.0 MB 550.9 kB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 6.6/11.0 MB 572.8 kB/s eta 0:00:08\n",
      "   ------------------------ --------------- 6.8/11.0 MB 589.1 kB/s eta 0:00:08\n",
      "   ------------------------- -------------- 7.1/11.0 MB 595.9 kB/s eta 0:00:07\n",
      "   --------------------------- ------------ 7.6/11.0 MB 634.8 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 7.6/11.0 MB 634.8 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 8.4/11.0 MB 671.9 kB/s eta 0:00:04\n",
      "   ------------------------------- -------- 8.7/11.0 MB 683.1 kB/s eta 0:00:04\n",
      "   -------------------------------- ------- 8.9/11.0 MB 690.3 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 9.4/11.0 MB 724.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 9.7/11.0 MB 739.2 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 10.0/11.0 MB 739.9 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 10.5/11.0 MB 768.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/11.0 MB 780.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/11.0 MB 780.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 771.5 kB/s eta 0:00:00\n",
      "Downloading albumentations-1.4.21-py3-none-any.whl (227 kB)\n",
      "Downloading albucore-0.0.20-py3-none-any.whl (12 kB)\n",
      "Downloading monai-1.4.0-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 0.8/1.5 MB 6.7 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.8/1.5 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 2.4 MB/s eta 0:00:00\n",
      "Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/15.8 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.0/15.8 MB 2.8 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 1.6/15.8 MB 3.0 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 2.4/15.8 MB 2.9 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 2.6/15.8 MB 2.6 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 2.9/15.8 MB 2.2 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 3.4/15.8 MB 2.3 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 4.2/15.8 MB 2.5 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 4.2/15.8 MB 2.5 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 5.2/15.8 MB 2.5 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 5.8/15.8 MB 2.6 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 6.0/15.8 MB 2.4 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 6.8/15.8 MB 2.4 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 7.6/15.8 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 7.9/15.8 MB 2.6 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 8.1/15.8 MB 2.4 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 8.7/15.8 MB 2.5 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 9.4/15.8 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 9.7/15.8 MB 2.4 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 10.5/15.8 MB 2.5 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 11.5/15.8 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 12.1/15.8 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 12.3/15.8 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 12.8/15.8 MB 2.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 13.6/15.8 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.4/15.8 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.4/15.8 MB 2.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.2/15.8 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.7/15.8 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 2.6 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading eval_type_backport-0.2.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading simsimd-6.1.1-cp311-cp311-win_amd64.whl (82 kB)\n",
      "Downloading stringzilla-3.10.10-cp311-cp311-win_amd64.whl (78 kB)\n",
      "Installing collected packages: stringzilla, simsimd, threadpoolctl, numpy, joblib, eval-type-backport, scikit-learn, monai, albucore, albumentations\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.2\n",
      "    Uninstalling numpy-2.1.2:\n",
      "      Successfully uninstalled numpy-2.1.2\n",
      "Successfully installed albucore-0.0.20 albumentations-1.4.21 eval-type-backport-0.2.0 joblib-1.4.2 monai-1.4.0 numpy-1.26.4 scikit-learn-1.5.2 simsimd-6.1.1 stringzilla-3.10.10 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "from segmentation_models_pytorch import UnetPlusPlus\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n"
   ],
   "id": "83f0af085f145436"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## MRI Data",
   "id": "14fe5ea26921bc9d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, image_paths, mask_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # obraz\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = pydicom.dcmread(image_path).pixel_array  # DICOM na macierz\n",
    "        image = cv2.resize(image, (256, 256))           # Zmiana rozmiaru na 256x256\n",
    "        image = np.expand_dims(image, axis=0) / 4095.0  # Normalizacja (12-bit -> [0,1])\n",
    "        \n",
    "        # maska\n",
    "        mask_path = self.mask_paths[idx]\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.resize(mask, (256, 256))\n",
    "        mask = np.expand_dims(mask, axis=0) / 255.0     # Normalizacja\n",
    "\n",
    "        # Augmentacja\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image[0], mask=mask[0])\n",
    "            image, mask = augmented[\"image\"], augmented[\"mask\"]\n",
    "\n",
    "        return torch.tensor(image, dtype=torch.float32), torch.tensor(mask, dtype=torch.float32)\n"
   ],
   "id": "b789359adfcb5469"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset\n",
   "id": "eaa304866a4cc0e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "image_dir = \"path_to_images\"\n",
    "mask_dir = \"path_to_masks\"\n",
    "\n",
    "image_paths = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith(\".dcm\")])\n",
    "mask_paths = sorted([os.path.join(mask_dir, f) for f in os.listdir(mask_dir) if f.endswith(\".png\")])\n",
    "\n",
    "train_images, val_images, train_masks, val_masks = train_test_split(image_paths, mask_paths, test_size=0.2, random_state=42)\n",
    "\n",
    "# Augmentacje\n",
    "from albumentations import Compose, HorizontalFlip, RandomBrightnessContrast\n",
    "transform = Compose([\n",
    "    HorizontalFlip(p=0.5),\n",
    "    RandomBrightnessContrast(p=0.2)\n",
    "])\n",
    "\n",
    "# Datasety\n",
    "train_dataset = MRIDataset(train_images, train_masks, transform=transform)\n",
    "val_dataset = MRIDataset(val_images, val_masks)\n",
    "\n",
    "# Loadery danych\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n"
   ],
   "id": "4eb5c7877a88d00"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## U-NET ++",
   "id": "6525d8dee850fd00"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from segmentation_models_pytorch import UnetPlusPlus\n",
    "\n",
    "class UNetPlusPlusModel(nn.Module):\n",
    "    def __init__(self, encoder_name=\"resnet34\", encoder_weights=\"imagenet\", in_channels=1, num_classes=1):\n",
    "        super(UNetPlusPlusModel, self).__init__()\n",
    "        self.model = UnetPlusPlus(\n",
    "            encoder_name=encoder_name,       # np. 'efficientnet-b4'\n",
    "            encoder_weights=encoder_weights, # np. 'imagenet' lub None\n",
    "            in_channels=in_channels,         # Liczba kanałów wejściowych (MRI = 1)\n",
    "            classes=num_classes               # Liczba klas wyjściowych\n",
    "        )\n",
    "        # Opcjonalne: dodatkowe warstwy wyjściowe\n",
    "        self.final_activation = nn.Sigmoid()  # Aktywacja końcowa (dla segmentacji binarnej)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return self.final_activation(x)\n",
    "\n",
    "# Inicjalizacja modelu\n",
    "model = UNetPlusPlusModel(\n",
    "    encoder_name=\"efficientnet-b0\",  # Wybierz encoder\n",
    "    encoder_weights=\"imagenet\",      # Wagi pretrained\n",
    "    in_channels=1,                   # MRI to obraz szarości\n",
    "    num_classes=1                    # Segmentacja binarna\n",
    ").cuda()  # GPU\n"
   ],
   "id": "6a82b77438f55719"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dropout i Batch Normalization",
   "id": "c7629b37465bbdbd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class UNetPlusPlusWithDropout(nn.Module):\n",
    "    def __init__(self, encoder_name=\"resnet34\", encoder_weights=\"imagenet\", in_channels=1, num_classes=1, dropout_rate=0.5):\n",
    "        super(UNetPlusPlusWithDropout, self).__init__()\n",
    "        self.model = UnetPlusPlus(\n",
    "            encoder_name=encoder_name,\n",
    "            encoder_weights=encoder_weights,\n",
    "            in_channels=in_channels,\n",
    "            classes=num_classes\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout_rate)  # Dropout\n",
    "        self.batch_norm = nn.BatchNorm2d(num_classes)  # Batch Normalization\n",
    "        self.final_activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.batch_norm(x)\n",
    "        return self.final_activation(x)\n",
    "\n",
    "# Inicjalizacja modelu\n",
    "model = UNetPlusPlusWithDropout(\n",
    "    encoder_name=\"resnet50\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=1,\n",
    "    num_classes=1,\n",
    "    dropout_rate=0.3\n",
    ").cuda()\n"
   ],
   "id": "b5acd1096d98e53"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Attention",
   "id": "3e33e5b498059506"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn = self.conv1(x)\n",
    "        attn = self.conv2(attn)\n",
    "        attn = self.sigmoid(attn)\n",
    "        return x * attn\n",
    "\n",
    "class UNetPlusPlusWithAttention(nn.Module):\n",
    "    def __init__(self, encoder_name=\"resnet34\", encoder_weights=\"imagenet\", in_channels=1, num_classes=1):\n",
    "        super(UNetPlusPlusWithAttention, self).__init__()\n",
    "        self.model = UnetPlusPlus(\n",
    "            encoder_name=encoder_name,\n",
    "            encoder_weights=encoder_weights,\n",
    "            in_channels=in_channels,\n",
    "            classes=num_classes\n",
    "        )\n",
    "        self.attention = AttentionBlock(num_classes, num_classes)\n",
    "        self.final_activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = self.attention(x)\n",
    "        return self.final_activation(x)\n",
    "\n",
    "# Inicjalizacja modelu\n",
    "model = UNetPlusPlusWithAttention(\n",
    "    encoder_name=\"resnet101\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=1,\n",
    "    num_classes=1\n",
    ").cuda()\n"
   ],
   "id": "970648dfcdb12b3c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Trening",
   "id": "94e3b9905f14736c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice = (2. * intersection + smooth) / (inputs.sum() + targets.sum() + smooth)\n",
    "        return 1 - dice\n",
    "\n",
    "criterion = DiceLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n"
   ],
   "id": "66d34628994f49cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train_model(model, train_loader, val_loader, epochs=20):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for images, masks in train_loader:\n",
    "            images, masks = images.cuda(), masks.cuda()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Walidacja\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for images, masks in val_loader:\n",
    "                images, masks = images.cuda(), masks.cuda()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}\")\n",
    "\n",
    "train_model(model, train_loader, val_loader, epochs=20)\n"
   ],
   "id": "7f67eafb70790a52"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Encoders + Test i visualization ",
   "id": "b26c82e56bf1fe3e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def test_encoders(encoders, data_loader, base_model_class):\n",
    "    \"\"\"\n",
    "    Testuje różne encodery i oblicza średni wynik Dice.\n",
    "    \n",
    "    :param encoders: Lista nazw encoderów do przetestowania.\n",
    "    :param data_loader: Loader danych walidacyjnych/testowych.\n",
    "    :param base_model_class: Klasa modelu (np. UnetPlusPlus z segmentation_models_pytorch).\n",
    "    :return: Lista słowników z wynikami {\"encoder\": encoder, \"dice_score\": avg_dice}.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for encoder in encoders:\n",
    "        print(f\"Testing encoder: {encoder}\")\n",
    "        \n",
    "        # Tworzenie modelu z wybranym encoderem\n",
    "        model = base_model_class(encoder_name=encoder, classes=1, activation=None)\n",
    "        model = model.cuda()\n",
    "        model.load_state_dict(torch.load(f\"best_model_{encoder}.pth\"))\n",
    "        \n",
    "        model.eval()\n",
    "        dice_scores = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, masks in data_loader:\n",
    "                images, masks = images.cuda(), masks.cuda()\n",
    "                outputs = model(images)\n",
    "                preds = torch.sigmoid(outputs).cpu().numpy()\n",
    "                preds = (preds > 0.5).astype(np.uint8)\n",
    "                \n",
    "                # Obliczanie metryki Dice\n",
    "                dice_score = (2 * np.sum(preds * masks.cpu().numpy()) + 1e-6) / \\\n",
    "                             (np.sum(preds) + np.sum(masks.cpu().numpy()) + 1e-6)\n",
    "                dice_scores.append(dice_score)\n",
    "        \n",
    "        avg_dice = np.mean(dice_scores)\n",
    "        print(f\"Average Dice Score for {encoder}: {avg_dice:.4f}\")\n",
    "        results.append({\"encoder\": encoder, \"dice_score\": avg_dice})\n",
    "    \n",
    "    return results\n"
   ],
   "id": "d188b7ca53c86b2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "2d911d32b1c68e22"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def visualize_predictions(model, data_loader, num_images=2):\n",
    "    \"\"\"\n",
    "    Wizualizuje predykcje modelu dla danych walidacyjnych/testowych.\n",
    "    \n",
    "    :param model: Wytrenowany model.\n",
    "    :param data_loader: Loader danych walidacyjnych/testowych.\n",
    "    :param num_images: Liczba przykładów do wizualizacji (domyślnie 2).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, masks in data_loader:\n",
    "            images, masks = images.cuda(), masks.cuda()\n",
    "            outputs = model(images)\n",
    "            preds = torch.sigmoid(outputs).cpu().numpy()\n",
    "            preds = (preds > 0.5).astype(np.uint8)\n",
    "\n",
    "            # Wizualizacja\n",
    "            for i in range(min(len(images), num_images)):\n",
    "                plt.figure(figsize=(10, 5))\n",
    "                plt.subplot(1, 3, 1)\n",
    "                plt.title(\"Input Image\")\n",
    "                plt.imshow(images[i].cpu().numpy().squeeze(), cmap='gray')\n",
    "\n",
    "                plt.subplot(1, 3, 2)\n",
    "                plt.title(\"Ground Truth\")\n",
    "                plt.imshow(masks[i].cpu().numpy().squeeze(), cmap='gray')\n",
    "\n",
    "                plt.subplot(1, 3, 3)\n",
    "                plt.title(\"Prediction\")\n",
    "                plt.imshow(preds[i].squeeze(), cmap='gray')\n",
    "                plt.show()\n"
   ],
   "id": "6147468b2e688a94"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from segmentation_models_pytorch import UnetPlusPlus\n",
    "\n",
    "# Lista encoderów do przetestowania\n",
    "encoders = [\"resnet34\", \"efficientnet-b0\", \"vgg16\"]\n",
    "\n",
    "# Testowanie encoderów\n",
    "results = test_encoders(encoders, val_loader, UnetPlusPlus)\n",
    "\n",
    "# Opcjonalna wizualizacja wyników dla najlepszego encodera\n",
    "best_encoder = max(results, key=lambda x: x[\"dice_score\"])[\"encoder\"]\n",
    "print(f\"Best encoder: {best_encoder}\")\n",
    "\n",
    "# Tworzenie modelu z najlepszym encoderem\n",
    "best_model = UnetPlusPlus(encoder_name=best_encoder, classes=1, activation=None)\n",
    "best_model = best_model.cuda()\n",
    "best_model.load_state_dict(torch.load(f\"best_model_{best_encoder}.pth\"))\n",
    "\n",
    "# Wizualizacja predykcji\n",
    "visualize_predictions(best_model, val_loader)\n"
   ],
   "id": "d6da8007d3156920"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
